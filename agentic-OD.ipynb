{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EeY1qYD19yKs"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch pillow einops\n",
        "!pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install pyvips-binary pyvips\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"vikhyatk/moondream2\",\n",
        "    revision=\"2025-03-27\",\n",
        "    trust_remote_code=True,\n",
        "    device_map={\"\": \"cuda\"}\n",
        ")"
      ],
      "metadata": {
        "id": "2L5MVNrD-D6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process all images in a folder\n",
        "def process_images_in_folder(folder_path, objects_to_detect):\n",
        "    annotations_path = os.path.join(folder_path, \"annotations\")\n",
        "\n",
        "    # Create the \"annotations\" folder if it doesn't exist\n",
        "    if not os.path.exists(annotations_path):\n",
        "        os.makedirs(annotations_path)\n",
        "\n",
        "    # Iterate through all the files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # Check if the file is a valid image\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Load the image\n",
        "            image = Image.open(image_path)\n",
        "            width, height = image.size\n",
        "\n",
        "            # Create a text file to save the results\n",
        "            txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "            txt_file_path = os.path.join(annotations_path, txt_filename)\n",
        "\n",
        "            results = []\n",
        "\n",
        "            for obj in objects_to_detect:\n",
        "                object_id = obj[\"id\"]  # Object's numerical ID\n",
        "                object_name = obj[\"name\"]  # Object's name\n",
        "\n",
        "                # Perform bounding box detection\n",
        "                result = model.detect(image, object_name)\n",
        "\n",
        "                # Add the bounding boxes to the results list with the numeric identifier\n",
        "                for bbox in result['objects']:\n",
        "                    x_min = int(bbox['x_min'] * width)\n",
        "                    y_min = int(bbox['y_min'] * height)\n",
        "                    x_max = int(bbox['x_max'] * width)\n",
        "                    y_max = int(bbox['y_max'] * height)\n",
        "\n",
        "                    results.append(f\"{object_id}, {x_min}, {y_min}, {x_max}, {y_max}\\n\")\n",
        "\n",
        "            # Write all the bounding boxes to the text file\n",
        "            with open(txt_file_path, 'w') as f:\n",
        "                f.writelines(results)\n",
        "\n",
        "\n",
        "# Specify the path to the folder containing the images\n",
        "dataset_folder = \"/content/dataset\"\n",
        "\n",
        "# Specify the classes to detect\n",
        "objects = [\n",
        "    {\"id\": 1, \"name\": \"car\"},\n",
        "    {\"id\": 2, \"name\": \"person\"},\n",
        "    {\"id\": 3, \"name\": \"bike\"},\n",
        "    {\"id\": 4, \"name\": \"van\"}\n",
        "]\n",
        "\n",
        "# Process all images in the folder\n",
        "process_images_in_folder(dataset_folder, objects)\n"
      ],
      "metadata": {
        "id": "RHjUW3-HAZDx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "dataset_folder = \"/content/dataset\"\n",
        "\n",
        "# Path for the zip file that will be created\n",
        "zip_path = '/content/dataset.zip'\n",
        "\n",
        "# Compress the folder into a .zip file\n",
        "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', dataset_folder)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-bq-Ktl6EPHe",
        "outputId": "6086ed10-fef3-47a2-d7e7-ec04605caf5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_948480ef-96f4-4bcb-8c16-0796f54b9be3\", \"dataset.zip\", 34423723)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}